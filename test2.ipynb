{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ AI Agent with Reasoning + Tool Use + RAG\n",
    "\n",
    "This agent uses:\n",
    "- Local **Llama3 via Ollama**\n",
    "- **RAG** with ChromaDB\n",
    "- A **weather tool** the LLM can decide to use\n",
    "- Chain-of-Thought style prompting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langchain chromadb requests llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and embed RAG docs\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "import os\n",
    "\n",
    "rag_docs = [\n",
    "    \"In Paris, it's best to carry an umbrella in spring.\",\n",
    "    \"Always check the local metro schedule to avoid delays.\",\n",
    "    \"Wear comfortable walking shoes when visiting tourist spots in Paris.\"\n",
    "]\n",
    "\n",
    "os.makedirs(\"rag_docs\", exist_ok=True)\n",
    "for i, text in enumerate(rag_docs):\n",
    "    with open(f\"rag_docs/doc_{i}.txt\", \"w\") as f:\n",
    "        f.write(text)\n",
    "\n",
    "all_docs = []\n",
    "for file in os.listdir(\"rag_docs\"):\n",
    "    loader = TextLoader(f\"rag_docs/{file}\")\n",
    "    all_docs.extend(loader.load())\n",
    "\n",
    "splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "splits = splitter.split_documents(all_docs)\n",
    "\n",
    "embedding = OllamaEmbeddings(model=\"llama3\")\n",
    "vectordb = Chroma.from_documents(splits, embedding, persist_directory=\"./chroma_db\")\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the free weather tool\n",
    "import requests\n",
    "\n",
    "def get_weather(lat: float, lon: float):\n",
    "    response = requests.get(\n",
    "        \"https://api.open-meteo.com/v1/forecast\",\n",
    "        params={\n",
    "            \"latitude\": lat,\n",
    "            \"longitude\": lon,\n",
    "            \"current\": \"temperature_2m,wind_speed_10m\",\n",
    "            \"temperature_unit\": \"celsius\",\n",
    "            \"windspeed_unit\": \"kmh\"\n",
    "        }\n",
    "    )\n",
    "    if response.status_code != 200:\n",
    "        return {\"error\": \"API failed.\"}\n",
    "    return response.json().get(\"current\", {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reasoning LLM setup\n",
    "from langchain.llms import Ollama\n",
    "llm = Ollama(model=\"llama3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create reasoning prompt using CoT + tool awareness\n",
    "question = (\n",
    "    \"You are a travel assistant. A user asks: 'What should I know before going to Paris today?'.\\n\"\n",
    "    \"You have access to background tips and a weather tool you may use if helpful.\\n\"\n",
    "    \"If you decide to call the weather tool, determine the correct latitude and longitude for the city.\\n\"\n",
    "    \"Answer step-by-step with reasoning.\"\n",
    ")\n",
    "\n",
    "response = llm.invoke(question)\n",
    "print(\"ü§î LLM Initial Reasoning:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: manually detect if LLM wants to call the tool\n",
    "# Simulate its next step by calling weather tool\n",
    "lat, lon = 48.8566, 2.3522  # Paris (LLM should have figured this)\n",
    "weather = get_weather(lat, lon)\n",
    "weather_text = f\"Temperature: {weather.get('temperature_2m', '?')}¬∞C, Wind: {weather.get('wind_speed_10m', '?')} km/h.\"\n",
    "print(\"\\nüå¶Ô∏è Simulated Weather Tool Output:\")\n",
    "print(weather_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final query combining tool result + RAG\n",
    "from langchain.chains import RetrievalQA\n",
    "retriever = Chroma(persist_directory=\"./chroma_db\", embedding_function=embedding).as_retriever()\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
    "\n",
    "query = (\n",
    "    f\"The weather in Paris today is: {weather_text}.\\n\"\n",
    "    f\"Based on this and local travel tips, what should a traveler know?\"\n",
    ")\n",
    "\n",
    "final_answer = qa.run(query)\n",
    "print(\"\\nüß† Final Agent Response:\")\n",
    "print(final_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
